---
title: "机器学习实操(以随机森林为例)"
author: "陈同"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
    theme: cerulean
    highlight: haddock
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: true
    code_fold: show
---

```{r, echo=F, eval=F}
rmarkdown::render("35.machinelearning.Rmd", output_format=rmarkdown::md_document(), output_file="35.machinelearning.md")
```


```{r, echo=F}
knitr::opts_chunk$set( echo = TRUE, message=FALSE, 
                       warning=FALSE, fig.width=8 )
```

```{r}
site = "https://mirrors.tuna.tsinghua.edu.cn/CRAN"

if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager", repos = site)

a = rownames(installed.packages())

options("repos"=c(CRAN="https://mirrors.tuna.tsinghua.edu.cn/CRAN/"))

install_bioc <-
  c(
    "caret", "randomForest", "Boruta", "ROCR","ggplot2",
    "verification","purrr","PRROC","pROC", "e1071"
  )

for (i in install_bioc) {
  if (!i %in% a){
    BiocManager::install(i, update = F, site_repository=site)
    a = rownames(installed.packages())
  }
}

if (!"ImageGP" %in% a){
  # devtools::install_github("Tong-Chen/ImageGP")
  devtools::install_git("https://gitee.com/ct5869/ImageGP.git")
}

library(conflicted)
conflict_prefer("intersect", "base")
```



## 机器学习实操(以随机森林为例) {#Acasestudymicroarraydata}


为了展示随机森林的操作，我们用一套早期的前列腺癌和癌旁基因表达芯片数据集，包含`102`个样品(50个正常，52个肿瘤)，`2`个分组和`9021`个变量 (基因)。（https://file.biolab.si/biolab/supp/bi-cancer/projections/info/prostata.html）

### 数据格式和读入数据 {#read_in_data}

输入数据为标准化之后的表达矩阵，基因在行，样本在列。随机森林对数值分布没有假设。每个基因表达值用于分类时是基因内部在不同样品直接比较，只要是样品之间标准化的数据即可，其他任何线性转换如`log2`，`scale`等都没有影响。

* 样品表达数据：[prostat.expr.txt](35_machine_learning/prostat.expr.symbol.txt)
* 样品分组信息：[prostat.metadata.txt](35_machine_learning/prostat.metadata.txt)

```{r}
expr_file <- "35_machine_learning/prostat.expr.symbol.txt"
metadata_file <- "35_machine_learning/prostat.metadata.txt"

# 每个基因表达值是内部比较，只要是样品之间标准化的数据即可，其它什么转换都关系不大
# 机器学习时，字符串还是默认为因子类型的好
expr_mat <- read.table(expr_file, row.names = 1, header = T, sep="\t", stringsAsFactors =T)

# 处理异常的基因名字
rownames(expr_mat) <- make.names(rownames(expr_mat))

metadata <- read.table(metadata_file, row.names=1, header=T, sep="\t", stringsAsFactors =T)

dim(expr_mat)
```

基因表达表示例如下：

```{r}
expr_mat[1:4,1:5]
```

Metadata表示例如下

```{r}
head(metadata)
tail(metadata)
```

```{r}
table(metadata)
```

### 样品筛选和排序 {#sampleSelectionAndOrder}

对读入的表达数据进行转置。通常我们是一行一个基因，一列一个样品。在构建模型时，数据通常是反过来的，一列一个基因，一行一个样品。每一列代表一个变量 (`variable`)，每一行代表一个案例 (`case`)。这样更方便提取每个变量，且易于把模型中的`x,y`放到一个矩阵中。

样本表和表达表中的样本顺序**对齐一致**也是需要确保的一个操作。

```{r}
# 表达数据转置
# 习惯上我们是一行一个基因，一列一个样品
# 做机器学习时，大部分数据都是反过来的，一列一个基因，一行一个样品
# 每一列代表一个变量
expr_mat <- t(expr_mat)
expr_mat_sampleL <- rownames(expr_mat)
metadata_sampleL <- rownames(metadata)



common_sampleL <- intersect(expr_mat_sampleL, metadata_sampleL)

# 保证表达表样品与METAdata样品顺序和数目完全一致
expr_mat <- expr_mat[common_sampleL,,drop=F]
metadata <- metadata[common_sampleL,,drop=F]

```

### 判断是分类还是回归 {#classificationOrRegression}

前面读数据时已经给定了参数`stringsAsFactors =T`，这一步可以忽略了。

* 如果group对应的列为数字，转换为数值型 - 做回归
* 如果group对应的列为分组，转换为因子型 - 做分类

```{r}
# R4.0之后默认读入的不是factor，需要做一个转换
# devtools::install_github("Tong-Chen/ImageGP")
library(ImageGP)

# 此处的class根据需要修改
group = "class"
group_order = c('tumor', 'normal')

# 如果group对应的列为数字，转换为数值型 - 做回归
# 如果group对应的列为分组，转换为因子型 - 做分类
if(numCheck(metadata[[group]])){
    if (!is.numeric(metadata[[group]])) {
      metadata[[group]] <- mixedToFloat(metadata[[group]])
    }
} else{
  metadata[[group]] <- factor(metadata[[group]], levels = group_order, ordered = T)
}



```

### 随机森林一般分析 {#randomForestTry}

```{r}
library(randomForest)

# 查看参数是个好习惯
# 有了前面的基础概述，再看每个参数的含义就明确了很多
# 也知道该怎么调了
# 每个人要解决的问题不同，通常不是别人用什么参数，自己就跟着用什么参数
# 尤其是到下游分析时
# ?randomForest

# 查看源码
# randomForest:::randomForest.default
```

加载包之后，直接分析一下，看到结果再调参。

```{r}
# 设置随机数种子，具体含义见 https://mp.weixin.qq.com/s/6plxo-E8qCdlzCgN8E90zg
set.seed(304)

# 直接使用默认参数
rf <- randomForest(expr_mat, metadata[[group]])
```

查看下初步结果, 随机森林类型判断为`分类`，构建了`500`棵树，每次决策时从随机选择的`94`个基因中做最优决策 (`mtry`)，`OOB`估计的错误率是`9.8%`，挺高的。

分类效果评估矩阵`Confusion matrix`,显示`normal`组的分类错误率为`0.06`，`tumor`组的分类错误率为`0.13`。

```{r}
rf
```

## 随机森林标准操作流程 (适用于其他机器学习模型)

### 拆分训练集和测试集

```{r}
library(caret)
seed <- 1
set.seed(seed)
train_index <- createDataPartition(metadata[[group]], p=0.75, list=F)
train_data <- expr_mat[train_index,]
train_data_group <- metadata[[group]][train_index]

test_data <- expr_mat[-train_index,]
test_data_group <- metadata[[group]][-train_index]
```

```{r}
dim(train_data)
```

```{r}
dim(test_data)
```

### Boruta特征选择鉴定关键分类变量

```{r}
# install.packages("Boruta")
library(Boruta)
set.seed(1)

boruta <- Boruta(x=train_data, y=train_data_group, pValue=0.01, mcAdj=T, 
       maxRuns=2000)

boruta
```


查看下变量重要性鉴定结果（实际上面的输出中也已经有体现了），`55`个重要的变量，`16`个可能重要的变量 (`tentative variable`, 重要性得分与最好的影子变量得分无统计差异)，`8,950`个不重要的变量。


```{r}
table(boruta$finalDecision)
```





绘制鉴定出的变量的重要性。变量少了可以用默认绘图，变量多时绘制的图看不清，需要自己整理数据绘图。

定义一个函数提取每个变量对应的重要性值。

```{r}
library(dplyr)
boruta.imp <- function(x){
  imp <- reshape2::melt(x$ImpHistory, na.rm=T)[,-1]
  colnames(imp) <- c("Variable","Importance")
  imp <- imp[is.finite(imp$Importance),]
  
  variableGrp <- data.frame(Variable=names(x$finalDecision), 
                            finalDecision=x$finalDecision)
  
  showGrp <- data.frame(Variable=c("shadowMax", "shadowMean", "shadowMin"),
                        finalDecision=c("shadowMax", "shadowMean", "shadowMin"))
  
  variableGrp <- rbind(variableGrp, showGrp)
  
  boruta.variable.imp <- merge(imp, variableGrp, all.x=T)
  
  sortedVariable <- boruta.variable.imp %>% group_by(Variable) %>% 
    summarise(median=median(Importance)) %>% arrange(median)
  sortedVariable <- as.vector(sortedVariable$Variable)
  
  
  boruta.variable.imp$Variable <- factor(boruta.variable.imp$Variable, levels=sortedVariable)
  
  invisible(boruta.variable.imp)
}
```

```{r}
boruta.variable.imp <- boruta.imp(boruta)

head(boruta.variable.imp)
```

只绘制`Confirmed`变量。

```{r borutavarimportance, fig.width=14}
library(ImageGP)

sp_boxplot(boruta.variable.imp, melted=T, xvariable = "Variable", yvariable = "Importance",
           legend_variable = "finalDecision", legend_variable_order = c("shadowMax", "shadowMean", "shadowMin", "Confirmed"),
           xtics_angle = 90)
```

提取重要的变量和可能重要的变量

```{r}
boruta.finalVarsWithTentative <- data.frame(Item=getSelectedAttributes(boruta, withTentative = T), Type="Boruta_with_tentative")
```


看下这些变量的值的分布

```{r, fig.width=20, fig.height=20}
caret::featurePlot(train_data[,boruta.finalVarsWithTentative$Item], train_data_group, plot="box")
```

### 交叉验证选择参数并拟合模型 {#borutaconfirmedvariablefit}

定义一个函数生成一些列用来测试的`mtry` (一系列不大于总变量数的数值)。

```{r}
generateTestVariableSet <- function(num_toal_variable){
  max_power <- ceiling(log10(num_toal_variable))
  tmp_subset <- c(unlist(sapply(1:max_power, function(x) (1:10)^x, simplify = F)), ceiling(max_power/3))
  #return(tmp_subset)
  base::unique(sort(tmp_subset[tmp_subset<num_toal_variable]))
}
# generateTestVariableSet(78)
```

选择关键特征变量相关的数据

```{r}
# 提取训练集的特征变量子集
boruta_train_data <- train_data[, boruta.finalVarsWithTentative$Item]
boruta_mtry <- generateTestVariableSet(ncol(boruta_train_data))
```

使用 Caret 进行调参和建模

```{r}
library(caret)
# Create model with default parameters

twoGroup = length(unique(train_data_group)) == 2

if (twoGroup) {
  trControl_roc <- trainControl(method="repeatedcv", number=10, repeats=5, classProbs = T,summaryFunction = twoClassSummary)
} else {
  trControl <- trainControl(method="repeatedcv", number=10, repeats=5)
}



seed <- 1
set.seed(seed)
# 根据经验或感觉设置一些待查询的参数和参数值
tuneGrid <- expand.grid(mtry=boruta_mtry)

if (twoGroup) {
  borutaConfirmed_rf_default <- train(x=boruta_train_data, y=train_data_group, method="rf", 
                                   tuneGrid = tuneGrid, # 
                                   metric="ROC", #metric='Kappa';Accuracy
                                   trControl=trControl_roc)
} else {
  borutaConfirmed_rf_default <- train(x=boruta_train_data, y=train_data_group, method="rf", 
                                    tuneGrid = tuneGrid, # 
                                    metric="Accuracy", #metric='Kappa';
                                    trControl=trControl)
}



borutaConfirmed_rf_default
```


可视化不同参数的准确性分布

```{r}
plot(borutaConfirmed_rf_default)
```

可视化Top20重要的变量

```{r}
dotPlot(varImp(borutaConfirmed_rf_default))
```

### 提取最终选择的模型，并绘制 ROC 曲线评估模型

```{r}
borutaConfirmed_rf_default_finalmodel <- borutaConfirmed_rf_default
```

#### 先自评，评估模型对训练集的分类效果

采用训练数据集评估构建的模型，`Accuracy=1; Kappa=1`，非常完美。


模型的预测显著性`P-Value [Acc > NIR] : 2.2e-16`。其中`NIR`是`No Information Rate`，其计算方式为数据集中最大的类包含的数据占总数据集的比例。如某套数据中，分组`A`有`80`个样品，分组`B`有`20`个样品，我们只要猜`A`，正确率就会有`80%`，这就是`NIR`。如果基于这套数据构建的模型准确率也是`80%`，那么这个看上去准确率较高的模型也没有意义。`confusionMatrix`使用`binom.test`函数检验模型的准确性`Accuracy`是否显著优于`NIR`，若`P-value<0.05`，则表示模型预测准确率显著高于随便猜测。 

```{r}
# 获得模型结果评估矩阵(`confusion matrix`)

predictions_train <- predict(borutaConfirmed_rf_default_finalmodel, newdata=train_data)
confusionMatrix(predictions_train, train_data_group)
```



#### 盲评，评估模型应用于测试集时的效果

绘制`ROC`曲线，计算模型整体的`AUC`值，并选择最佳模型。

```{r}
# 绘制ROC曲线

prediction_prob <- predict(borutaConfirmed_rf_default_finalmodel, newdata=test_data, type="prob")
library(pROC)
roc_curve <- roc(test_data_group, prediction_prob[,1])

roc_curve
```

```{r}
# roc <- roc(test_data_group, factor(predictions, ordered=T))
# plot(roc)
```

##### 基于默认阈值的盲评

基于默认阈值绘制混淆矩阵并评估模型预测准确度显著性,结果显著`P-Value [Acc > NIR]<0.05`。

```{r}
# 获得模型结果评估矩阵(`confusion matrix`)

predictions <- predict(borutaConfirmed_rf_default_finalmodel, newdata=test_data)
confusionMatrix(predictions, test_data_group)
```

##### 选择模型分类最佳阈值再盲评

* youden: $max(sensitivities + r \times specificities)$
* closest.topleft: $min((1 - sensitivities)^2 + r \times (1- specificities)^2)$

`r`是加权系数，默认是`1`，其计算方式为$r = (1 - prevalence) / (cost * prevalence)$.

`best.weights`控制加权方式：(`cost`, `prevalence`)默认是(`1`, `0.5`)，据此算出的`r`为`1`。

* *cost*: 假阴性率占假阳性率的比例，容忍更高的假阳性率还是假阴性率

* *prevalence*: 关注的类中的个体所占的比例 (`n.cases/(n.controls+n.cases)`).


```{r}
best_thresh <- data.frame(coords(roc=roc_curve, x = "best", input="threshold", 
                                 transpose = F, best.method = "youden",
                                 best.weights=c(0.5, 0.5)))

best_thresh$best <- apply(best_thresh, 1, function (x) 
  paste0('threshold: ', x[1], ' (', round(1-x[2],3), ", ", round(x[3],3), ")"))

# best_thresh不改变ROC曲线，但会影响混淆矩阵 confusion matrix
best_thresh
```

准备数据绘制ROC曲线

```{r}
library(ggrepel)
ROC_data <- data.frame(FPR = 1- roc_curve$specificities, TPR=roc_curve$sensitivities)
ROC_data <- ROC_data[with(ROC_data, order(FPR,TPR)),]


p <- ggplot(data=ROC_data, mapping=aes(x=FPR, y=TPR)) +
  geom_step(color="red", size=1, direction = "vh") +
  geom_segment(aes(x=0, xend=1, y=0, yend=1))  + theme_classic() + 
  xlab("False positive rate") + 
  ylab("True positive rate") + coord_fixed(1) + xlim(0,1) + ylim(0,1) +
  annotate('text', x=0.5, y=0.25, label=paste('AUC=', round(roc_curve$auc,2))) +
  geom_point(data=best_thresh, mapping=aes(x=1-specificity, y=sensitivity), color='blue', size=2) + 
  geom_text_repel(data=best_thresh, mapping=aes(x=1.05-specificity, y=sensitivity ,label=best))
p
```


基于选定的最优阈值制作混淆矩阵并评估模型预测准确度显著性,结果显著`P-Value [Acc > NIR]<0.05`。

```{r}
predict_result <- data.frame(Predict_status=c(T,F), Predict_class=colnames(prediction_prob))

head(predict_result)

predictions2 <- plyr::join(data.frame(Predict_status=prediction_prob[,1] > best_thresh[1,1]), predict_result)

predictions2 <- as.factor(predictions2$Predict_class)

confusionMatrix(predictions2, test_data_group)
```

### Caret + logistic regression


```{r}
library(caret)
# Create model with default parameters

twoGroup = length(unique(train_data_group)) == 2

if (twoGroup) {
  trControl_roc <- trainControl(method="repeatedcv", number=10, repeats=5, classProbs = T,summaryFunction = twoClassSummary)
} else {
  trControl <- trainControl(method="repeatedcv", number=10, repeats=5)
}



seed <- 1
set.seed(seed)
# 根据经验或感觉设置一些待查询的参数和参数值
tuneGrid <- expand.grid(mtry=boruta_mtry)

if (twoGroup) {
  borutaConfirmed_lb_default <- train(x=boruta_train_data, y=train_data_group, method="LogitBoost", 
                                   metric="ROC", #metric='Kappa';Accuracy
                                   trControl=trControl_roc)
} else {
  borutaConfirmed_lb_default <- train(x=boruta_train_data, y=train_data_group, method="LogitBoost", 
                                    metric="Accuracy", #metric='Kappa';
                                    trControl=trControl)
}


borutaConfirmed_lb_default_finalmodel <- borutaConfirmed_lb_default

# 绘制ROC曲线

prediction_prob <- predict(borutaConfirmed_lb_default_finalmodel, newdata=test_data, type="prob")
library(pROC)
roc_curve <- roc(test_data_group, prediction_prob[,1])

roc_curve

# 获得模型结果评估矩阵(`confusion matrix`)
predictions <- predict(borutaConfirmed_lb_default_finalmodel, newdata=test_data)
confusionMatrix(predictions, test_data_group)


library(ggrepel)
ROC_data <- data.frame(FPR = 1- roc_curve$specificities, TPR=roc_curve$sensitivities)
ROC_data <- ROC_data[with(ROC_data, order(FPR,TPR)),]

best_thresh <- data.frame(coords(roc=roc_curve, x = "best", input="threshold", 
                                 transpose = F, best.method = "youden",
                                 best.weights=c(0.5, 0.5)))

best_thresh$best <- apply(best_thresh, 1, function (x) 
  paste0('threshold: ', x[1], ' (', round(1-x[2],3), ", ", round(x[3],3), ")"))

best_thresh

p <- ggplot(data=ROC_data, mapping=aes(x=FPR, y=TPR)) +
  geom_step(color="red", size=1, direction = "vh") +
  geom_segment(aes(x=0, xend=1, y=0, yend=1))  + theme_classic() + 
  xlab("False positive rate") + 
  ylab("True positive rate") + coord_fixed(1) + xlim(0,1) + ylim(0,1) +
  annotate('text', x=0.5, y=0.25, label=paste('AUC=', round(roc_curve$auc,2))) +
  geom_point(data=best_thresh, mapping=aes(x=1-specificity, y=sensitivity), color='blue', size=2) + 
  geom_text_repel(data=best_thresh, mapping=aes(x=1.05-specificity, y=sensitivity ,label=best))
p





predict_result <- data.frame(Predict_status=c(T,F), Predict_class=colnames(prediction_prob))

head(predict_result)

predictions2 <- plyr::join(data.frame(Predict_status=prediction_prob[,1] > best_thresh[1,1]), predict_result)

predictions2 <- as.factor(predictions2$Predict_class)

confusionMatrix(predictions2, test_data_group)
```



